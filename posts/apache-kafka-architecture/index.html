<!doctype html><html lang=en><head><title>Apache Kafka in 15 minutes · Jens Rantil
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Jens Rantil"><meta name=description content="High-level Apache Kafka architecture."><meta name=keywords content="blog,developer,staff engineering,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Apache Kafka in 15 minutes"><meta name=twitter:description content="High-level Apache Kafka architecture."><meta property="og:url" content="https://jensrantil.github.io/posts/apache-kafka-architecture/"><meta property="og:site_name" content="Jens Rantil"><meta property="og:title" content="Apache Kafka in 15 minutes"><meta property="og:description" content="High-level Apache Kafka architecture."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-02-22T20:23:35+02:00"><meta property="article:modified_time" content="2025-09-09T13:51:54+02:00"><meta property="article:tag" content="Apache Kafka"><meta property="article:tag" content="Distributed Systems"><link rel=canonical href=https://jensrantil.github.io/posts/apache-kafka-architecture/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.7763f8bc6341ecf82378e867c285e1549abb063a899be313ccd25dbfcd24fa7d.css integrity="sha256-d2P4vGNB7PgjeOhnwoXhVJq7BjqJm+MTzNJdv80k+n0=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=stylesheet href=/custom.min.2e198fefc57dcc517a51f5b2040b841f014759bd551d4dd18df6dd0c1b954a62.css integrity="sha256-LhmP78V9zFF6UfWyBAuEHwFHWb1VHU3RjfbdDBuVSmI=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://jensrantil.github.io/>Jens Rantil
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=/pages/services/>Services</a></li><li class=navigation-item><a class=navigation-link href=/pages/about-me/>About</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://jensrantil.github.io/posts/apache-kafka-architecture/>Apache Kafka in 15 minutes</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2025-02-22T20:23:35+02:00>February 22, 2025
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
5-minute read</span></div><div class=categories><i class="fa-solid fa-folder" aria-hidden=true></i>
<a href=/categories/apache-kafka-load-balancing/>Apache Kafka Load-Balancing</a></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/apache-kafka/>Apache Kafka</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/distributed-systems/>Distributed Systems</a></span></div></div></header><div class=post-content><p>This post will be the first in a series of blog posts where I will be talking about the limitations of <a href=https://kafka.apache.org class=external-link target=_blank rel=noopener>Apache Kafka</a> as a task queue and how we overcame these limitations at a previous employer where I managed tens of fairly high-throughput Apache Kafka clusters. This post will lay the groundwork for explaining how Apache Kafka works, such that the rest of the posts are easy to follow.</p><p>Hopefully, these articles will avoid future battle scars for people who dabble with Apache Kafka. &#x2764;&#xfe0f; &#x1f915;</p><h2 id=high-level-concepts>High-level concepts
<a class=heading-link href=#high-level-concepts><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><figure><img id=service-arch src=/posts/apache-kafka-architecture/service-architecture-0.svg alt="The Apache Kafka diagram represents a high-level architecture showing how data flows between producers, topics, brokers, and consumers. On the left, multiple producers generate and send data to Kafka topics, which act as logical channels for organizing records. These topics are managed by Kafka brokers, which distribute and store the data across partitions for scalability and fault tolerance. On the right, consumers subscribe to specific topics and retrieve data in real time, often as part of consumer groups that distribute the load across multiple instances. Additional components such as connectors and stream processors may be present, enabling integrations with external systems and real-time data transformations. The overall flow illustrates how Kafka enables decoupled, scalable, and reliable event-driven architectures."><figcaption><p>A high-level architecture of Apache Kafka. The arrows show how records flow through the system.</p></figcaption></figure><script>archCount=0;function update_arch_svg(){src="/posts/apache-kafka-architecture/service-architecture-"+archCount+".svg",document.getElementById("service-arch").setAttribute("src",src),nStates=6,archCount=(archCount+1)%nStates,setTimeout(update_arch_svg,1e3)}update_arch_svg()</script><p>Apache Kafka (from now on, referred to as &ldquo;Kafka&rdquo;), is a system that asynchronously transports messages from a set of <strong>producers</strong> to a set of <strong>consumers</strong>. &ldquo;Messages&rdquo; are, in Kafka lingo, called <strong>records</strong>. A Kafka cluster consists of a set of <strong>brokers</strong>. Each record passes through a broker<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. Each broker stores the records to disk such that consumers can consume them at a later stage. I will go more into detail about how a broker works later.</p><p>Like most message-passing systems, Kafka also has the concept of a <strong>topic</strong>. Topics are used to organise the records stored in a Kafka cluster. Every record sent to a Kafka cluster has a topic destination. To consume that record, a consumer must use the same topic name. For example, if you are running a website analytics company, you might have a topic called <code>user_clicks</code> that contains all the tracked events of website visitors.</p><p>A topic is split up into <strong>partitions</strong>. Each partition is associated with a broker<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. A broken can have multiple partitions assigned to it. As depicted in the figure above, this means that there <em>can</em> be brokers that do not store any records for a specific topic.</p><p>Partitions are the core concept that allows Kafka to scale horizontally. Incoming records are assigned to a partition and, through that, a broker. Which partition a record is routed to is up to the producer of the record to decide. Each message has an optional <strong>key</strong>. If the key is null, the message is sent to a random partition (ie, Round-Robin). If the key is set to a string, the producer picks a partition based on a hash of the key (ie, something like <code>partition := hash(record.key) % numberOfPartitions</code>).</p><p>Each consumer belongs to a <strong>consumer group</strong>, and each consumer group is associated with a topic. Every record will be sent to one consumer in each consumer group. This means that each consumer group for topix X will, as a whole, receive every record for topix X. This allows for <em>fan-out</em> such that you can have multiple downstream consumer systems that each process every message. In the case of the website analytics company, you might have one downstream consumer group that triggers alerts and another consumer group that generates hourly website statistics that can be graphed. Each of these two systems receives all the user events.</p><p>Okay, so far, I have described a horizontally scalable message-passing system supporting fan-out. I have left out one particular detail, which is how partitions and consumers relate. To be able to explain that, I need to talk about how brokers store their data.</p><h2 id=the-partition-log>The partition log
<a class=heading-link href=#the-partition-log><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><figure><img src=/posts/apache-kafka-architecture/log.svg alt="A figure depicting a log with indexed records stacked from left to right. There is an arrow at the far right that signals that messages are appended."><figcaption><p>An append-only log of records. Each record has an index called &lsquo;offset&rsquo;.</p></figcaption></figure><p>Each partition on a broker is stored as a <strong>log</strong> on disk. A log is an append-only file where each record gets added at the end. Each record has an implicit <strong>offset</strong> counting from the start of the log.</p><p>To avoid needing to store all records for infinity, the on-disk log file is chunked up in something like ~100MB files<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>. Files older than a configurable <abbr title="Time To Live">TTL</abbr> are deleted. It&rsquo;s worth pointing out that the record&rsquo;s offset remains the same. Another important thing to notice here is that <strong>no messages are deleted once they have been consumed by all subscribed consumers</strong>.</p><p>Consumers simply stream the records from this log. Since writing to disk and reading is done by append-only and streaming, Kafka has a high-throughput.</p><h2 id=consumer-partitions>Consumer partitions
<a class=heading-link href=#consumer-partitions><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><figure><img src=/posts/apache-kafka-architecture/partition-consumers.svg alt="A figure depicting a log with indexed records stacked from left to right. There is an arrow at the far right that signals that messages are appended. There are also two consumer groups pointing to specific offsets."><figcaption><p>An append-only log of records, showing the last processed record for each consumer group.</p></figcaption></figure><p>The way Kafka keeps track of which records have been consumed is by, for each consumer group, keeping a reference to each partition&rsquo;s last offset that it has consumed. I tend to think of Kafka&rsquo;s internal representation as something like this:</p><pre tabindex=0><code>consumer_groups:
  X:
    partitions:
      0: 88
      1: 65
      2: 23
      4: 32
      5: 103
  Y:
    partitions:
      0: 83
      1: 61
      2: 37
      4: 42
      5: 112
</code></pre><p>As soon as consumer group X has processed record 66 in partition 1, it updates <code>consumer_groups.X.partitions.1</code> to <code>66</code>.</p><p>To avoid contention in incrementing these consumer offsets, <strong>every partition is assigned to one consumer</strong> in each consumer group. It is up to each consumer to update these offsets whenever they want (every minute, every message, after 10 messages, etc.). This means that <em>there is only one consumer per consumer group that consumes each partition</em>. This has immense implications, which my next blog post will be about.</p><h2 id=further-reading>Further reading
<a class=heading-link href=#further-reading><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li><a href=https://kafka.apache.org/documentation#gettingStarted class=external-link target=_blank rel=noopener>Key Concepts</a> from Kafka&rsquo;s documentation.</li><li><a href=https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying[]%28[]%28%29%29 class=external-link target=_blank rel=noopener>The Log: What every software engineer should know about real-time data&rsquo;s unifying abstraction</a> by Jay Keps. A great long-form article about the insights leading up to Apache Kafka.</li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Strictly speaking, each record usually passes through <em>multiple</em> brokers for redundancy reasons. That said, to keep this article simple, we can ignore that for now.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Actually, every partition is associated with <em>multiple</em> brokers for redundancy reasons. This means that every record is written to <em>all</em> brokers for a specific partition. That said, for simplicity, let&rsquo;s just assume that there is just one broker per partition for now.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>The chunk size is configurable.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer></footer></article></section></div><footer class=footer><section class=container>©
2026
Jens Rantil
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.
[<a href=https://github.com/JensRantil/jensrantil.github.io/tree/42d9021522720a0862feb830381f3a25441db542 target=_blank rel=noopener>42d9021</a>]</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-8QE7N3YHJ3"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8QE7N3YHJ3")</script></body></html>