<!doctype html><html lang=en><head><title>Testing strategy over time · Jens Rantil
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Jens Rantil"><meta name=description content="Last year (2019) I spent a fair amount of time thinking about how to grow
Tink&rsquo;s technical platform; how to organise ourselves
&ndash; alignment vs. autonomy.  What processes, tooling, and policies were needed
for our teams to build amazing, stable, performant things at a fast pace? Tink
had essentially doubled in size yearly for four years and the growth had really
pushed our engineering organization to the limits. We are now around 150
engineers. We were less than 10 engineers when I started in early 2014."><meta name=keywords content="blog,developer,staff engineering,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Testing strategy over time"><meta name=twitter:description content="Last year (2019) I spent a fair amount of time thinking about how to grow Tink’s technical platform; how to organise ourselves – alignment vs. autonomy. What processes, tooling, and policies were needed for our teams to build amazing, stable, performant things at a fast pace? Tink had essentially doubled in size yearly for four years and the growth had really pushed our engineering organization to the limits. We are now around 150 engineers. We were less than 10 engineers when I started in early 2014."><meta property="og:url" content="https://jensrantil.github.io/posts/testing-strategy-over-time/"><meta property="og:site_name" content="Jens Rantil"><meta property="og:title" content="Testing strategy over time"><meta property="og:description" content="Last year (2019) I spent a fair amount of time thinking about how to grow Tink’s technical platform; how to organise ourselves – alignment vs. autonomy. What processes, tooling, and policies were needed for our teams to build amazing, stable, performant things at a fast pace? Tink had essentially doubled in size yearly for four years and the growth had really pushed our engineering organization to the limits. We are now around 150 engineers. We were less than 10 engineers when I started in early 2014."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-01-12T00:00:00+00:00"><meta property="article:modified_time" content="2025-11-06T10:47:44+01:00"><meta property="article:tag" content="Testing"><link rel=canonical href=https://jensrantil.github.io/posts/testing-strategy-over-time/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.7763f8bc6341ecf82378e867c285e1549abb063a899be313ccd25dbfcd24fa7d.css integrity="sha256-d2P4vGNB7PgjeOhnwoXhVJq7BjqJm+MTzNJdv80k+n0=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=stylesheet href=/custom.min.2e198fefc57dcc517a51f5b2040b841f014759bd551d4dd18df6dd0c1b954a62.css integrity="sha256-LhmP78V9zFF6UfWyBAuEHwFHWb1VHU3RjfbdDBuVSmI=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://jensrantil.github.io/>Jens Rantil
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=/pages/services/>Services</a></li><li class=navigation-item><a class=navigation-link href=/pages/about-me/>About</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://jensrantil.github.io/posts/testing-strategy-over-time/>Testing strategy over time</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2020-01-12T00:00:00Z>January 12, 2020
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
5-minute read</span></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/testing/>Testing</a></span></div></div></header><div class=post-content><p>Last year (2019) I spent a fair amount of time thinking about how to grow
<a href=https://www.tinkapp.com class=external-link target=_blank rel=noopener>Tink&rsquo;s</a> technical platform; how to organise ourselves
&ndash; alignment vs. autonomy. What processes, tooling, and policies were needed
for our teams to build amazing, stable, performant things at a fast pace? Tink
had essentially doubled in size yearly for four years and the growth had really
pushed our engineering organization to the limits. We are now around 150
engineers. We were less than 10 engineers when I started in early 2014.</p><blockquote><p>What are the foundational building blocks and processes needed for us to have
twice as many teams in a year&rsquo;s time?</p></blockquote><p>The technical platform has grown from a Java monolith consisting of a few
services that mostly were deployed at the same time, to almost 100 polyglot
services (mostly microservices) being deployed continuously by lots of teams.</p><p>One thing that changes once you move towards a microservice architecture is
testing. Large-scale system testing involving many applications, owned by many
different teams, becomes increasingly difficult.</p><p>As I was thinking about testing strategy, I decided to give a talk at the
<a href=https://www.meetup.com/Go-Stockholm/events/260663183/ class=external-link target=_blank rel=noopener>Stockholm Go Meetup</a> on
how we do testing at Tink (<a href=testing-at-tink.pdf>slides</a>). Ignoring the fact
that the slides barely were readable (sorry!), my intention was to talk about</p><ol><li>the different types of tests there are; and</li><li>the different tradeoffs we are
making when choosing different testing strategies.</li></ol><p>The talk itself came out of
an observation that a lot of developers have strong opinions about testing.
However, we rarely talk about what it&rsquo;s actually trying to achieve, or which
contexts different software can be in.</p><p>The talk started with presenting a small variant of the classical test Pyramid:</p><p><a href=pyramid.png><img src=/posts/testing-strategy-over-time/pyramid.png alt="The Test Pyramid"></a></p><p>A difference between the test pyramid above and the classical test pyramid is
that it distinguishes between &ldquo;narrow integration tests&rdquo; and &ldquo;wide integration
tests&rdquo;. Martin Fowler has written a great
<a href=https://martinfowler.com/bliki/IntegrationTest.html class=external-link target=_blank rel=noopener>article</a> about the
concept of narrow integration tests. I have more to say about that, but I&rsquo;ll
leave that to another blog post.</p><p>My presentation then continued making a bunch of small observations about the
pyramid. Namely, the higher up in the pyramid you are, the</p><ul><li>the fewer tests compared to the base (thus, a Pyramid).</li><li>the <strong>slower feedback</strong> you will get as tests are slower to execute.</li><li>the <strong>more brittle</strong> your tests will become as they involve more components.
This means they break more easily as they are coupled to a larger
implementation surface is.</li><li>the higher probability of your tests being <strong>flaky</strong>. Timeouts to a
database, or starting up a web server, etc., become more common. Tests also
tend to become less deterministic.</li><li><strong>more maintenance is needed</strong> as more components are involved.</li><li><strong>harder it becomes to debug</strong> as more components are involved.</li><li><strong>slower the tests</strong> tend to be to run as they need to initialize more
components. System tests might need to read up data from a disk or external
database to function.</li><li><strong>more complex they are to run</strong>. System tests might need configuration to
run.</li><li><strong>closer you are to production</strong>.</li><li><strong>higher coverage per test</strong> as each test generally touches more components.</li><li><strong>harder it gets to reach higher levels of test coverage</strong>. By this, I don&rsquo;t
mean 100% test coverage is a goal. For a long time at Tink, we were rather
system tests heavy. When we started running the same application across many
production environments, running our system tests for all combinations of
configurations became impossible.</li></ul><p>Additionally, I also observed that tests in the lower part of the pyramid
require &ldquo;low coupling and high cohesion&rdquo; (LCHC), generally considered good
software design practices. That said, it <em>is</em> possible to have low coupling and
high cohesion in an application that lacks integration and/or unit tests.</p><p>The fact that LCHC is required for unit tests and narrow integration tests also
means that <a href=http://www.laputan.org/mud/ class=external-link target=_blank rel=noopener>big balls</a> <a href=https://en.wikipedia.org/wiki/Big_ball_of_mud class=external-link target=_blank rel=noopener>of
mud</a> are very hard to test with
such tests. For teams inheriting balls of mud it therefore makes sense to focus
on a blackbox system and/or acceptance tests so they can then refactor the
application to allow for smaller tests.</p><p>Furthermore, I observed how different types of tests&rsquo; costs change as software
complexity increases:</p><p><a href=testing-costs.png><img src=/posts/testing-strategy-over-time/testing-costs.png alt="The cost of maintaining the system and wide integration tests increases with software complexity. Narrow integration and unit tests do not."></a></p><p>The assumption here in the graph is that an &ldquo;Integration test&rdquo; depends on a
fixed number of components. Therefore the cost of maintaining such tests does
not grow as the software gets more components. This leads to the following
benefit/cost ratio:</p><p><a href=testing-value.png><img src=/posts/testing-strategy-over-time/testing-value.png alt="Value of different types of tests as software complexity increases. The benefit/cost ratio of system and wide integration tests is decreased with increased software complexity. Narrow integration and unit tests do not."></a></p><p>My experience over the years is that software complexity tends to grow over
time. New requirements & features tend to be added, and fewer are removed.
Additionally, rewrites to simplify something are rare. For good reasons! The
risks in doing a rewrite are huge.</p><p>This insight is key. I believe it explains why our community is so fragmented
when it comes to testing strategy &ndash; it&rsquo;s because testing <em>strategy must change
with software complexity</em>! Engineers who only have experience of low-complex
software will argue for investing in a few high-level systems or wide
integration tests. Engineers with experience with high complexity, tend to be
wary of such tests and instead prefer unit tests and narrow integration tests.</p><p>But the reality is that none of the engineers are right. The distribution of
different test types is not fixed. Instead, it changes over the life of a
software. Initially, when developing a tiny microservice, I found that a single
system test gives me huge benefits. As my software grows, I implement fewer and
fewer system and wide integration tests &ndash; they become increasingly painful to
work with.</p><p>Is there a way to avoid having to change the testing strategy over time?
Perhaps. Avoid introducing complexity or make sure your core developers stay
around:</p><p>With the advent of microservices, some companies have a cultural preference to
keep their services small. To some extent, this can keep complexity down at the
service level. However, it&rsquo;s worth remembering that that instead pushes complexity to live <em>between</em> microservices instead. For example, investments in observability become
increasingly important.</p><p>You can partially also avoid hitting the costs of software complexity by making
sure you keep core competencies about an application around. Training can also,
to some extent, help. That said, you are playing a rather risky game here as
developers will eventually come and go. Eventually, complexity will come back
biting you in the back.</p></div><footer></footer></article></section></div><footer class=footer><section class=container>©
2026
Jens Rantil
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.
[<a href=https://github.com/JensRantil/jensrantil.github.io/tree/c18e2e7d974aa85e54d5a8e16aac76ba15f462eb target=_blank rel=noopener>c18e2e7</a>]</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-8QE7N3YHJ3"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8QE7N3YHJ3")</script></body></html>